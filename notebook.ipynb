{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis on IMDB large movie review dataset\n",
    "\n",
    "Get the dataset from [here](http://ai.stanford.edu/~amaas/data/sentiment/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/code/venvs/data3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "from IPython.display import SVG\n",
    "\n",
    "from keras import models, layers\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text(text):\n",
    "    return text.lower().strip()\n",
    "\n",
    "def read_and_append_files(folder, label):\n",
    "    texts = []\n",
    "    for file in glob('./aclImdb/{0}/*.txt'.format(folder)):\n",
    "        with open(file, 'r') as f:\n",
    "            text = f.read()\n",
    "            text = parse_text(text)\n",
    "            texts.append((text, label))\n",
    "            \n",
    "    return texts\n",
    "\n",
    "def make_df(pos, neg):\n",
    "    df = pd.concat([pd.DataFrame(pos),\n",
    "                    pd.DataFrame(neg)])\\\n",
    "           .sample(frac=1)\\\n",
    "           .reset_index(drop=True)\n",
    "    df.columns = ['review', 'label']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = read_and_append_files('train/pos', 1)\n",
    "train_neg = read_and_append_files('train/neg', 0)\n",
    "\n",
    "test_pos = read_and_append_files('test/pos', 1)\n",
    "test_neg = read_and_append_files('test/neg', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = make_df(train_pos, train_neg)\n",
    "test_df = make_df(test_pos, test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i've been trying to find out about this series...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>secret sunshine marks the return of director l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the clouded yellow is a compact psychological ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maybe i'm biased to foxes, fox stories and all...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>every kid has that movie that he pops into vhs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  i've been trying to find out about this series...      1\n",
       "1  secret sunshine marks the return of director l...      1\n",
       "2  the clouded yellow is a compact psychological ...      1\n",
       "3  maybe i'm biased to foxes, fox stories and all...      1\n",
       "4  every kid has that movie that he pops into vhs...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ah, here it is! a movie, which is said by peop...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>after watch this movie i was surprised that so...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>william shakespeare probably didn't envision s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"four daughters,\" a sentimental story of a sol...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great movie. i was laughing all time through. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  ah, here it is! a movie, which is said by peop...      0\n",
       "1  after watch this movie i was surprised that so...      0\n",
       "2  william shakespeare probably didn't envision s...      1\n",
       "3  \"four daughters,\" a sentimental story of a sol...      1\n",
       "4  great movie. i was laughing all time through. ...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "I use [Fast Text pre trained embeddings](https://fasttext.cc/docs/en/english-vectors.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(train_df['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(fname, word_index):\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "    \n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        if tokens[0] in word_index:\n",
    "            w = word_index[tokens[0]]\n",
    "            embedding_matrix[w] = np.fromiter(map(float, tokens[1:]), 'float')\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.5 s, sys: 422 ms, total: 13.9 s\n",
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%time vectors = load_vectors('./wiki-news-300d-1M.vec', t.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = t.texts_to_matrix(train_df['review'])\n",
    "y_train = train_df['label']\n",
    "\n",
    "x_test = t.texts_to_matrix(test_df['review'])\n",
    "y_test = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 88566), (25000,), (25000, 88566), (25000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = layers.Input(shape=(x_train.shape[1],))\n",
    "h = layers.Dense(units=1, activation='sigmoid')(i)\n",
    "model = models.Model(inputs=[i], outputs=[h])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "# SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 36s 1ms/step - loss: 0.5731 - binary_accuracy: 0.7910 - val_loss: 0.5044 - val_binary_accuracy: 0.8171\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 76s 3ms/step - loss: 0.4611 - binary_accuracy: 0.8375 - val_loss: 0.4449 - val_binary_accuracy: 0.8340\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 52s 2ms/step - loss: 0.4135 - binary_accuracy: 0.8515 - val_loss: 0.4101 - val_binary_accuracy: 0.8464\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 42s 2ms/step - loss: 0.3850 - binary_accuracy: 0.8603 - val_loss: 0.3906 - val_binary_accuracy: 0.8511\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 65s 3ms/step - loss: 0.3653 - binary_accuracy: 0.8666 - val_loss: 0.3753 - val_binary_accuracy: 0.8560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f951967d908>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train,\n",
    "          y=y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Embeddings and multi layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(t.texts_to_sequences(train_df['review']), maxlen=500)\n",
    "y_train = train_df['label']\n",
    "\n",
    "x_test = pad_sequences(t.texts_to_sequences(test_df['review']), maxlen=500)\n",
    "y_test = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 500), (25000,), (25000, 500), (25000,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = layers.Input(shape=(x_train.shape[1],))\n",
    "\n",
    "embedding_layer = layers.Embedding(input_dim=vectors.shape[0],\n",
    "                                   output_dim=vectors.shape[1],\n",
    "                                   weights=[vectors],\n",
    "                                   trainable=False)\n",
    "\n",
    "h = embedding_layer(i)\n",
    "h = layers.Lambda(lambda r: K.mean(r, axis=1))(h)\n",
    "h = layers.Dense(128, activation='relu')(h)\n",
    "h = layers.Dropout(0.3)(h)\n",
    "h = layers.Dense(32, activation='relu')(h)\n",
    "h = layers.Dropout(0.3)(h)\n",
    "h = layers.Dense(1, activation='sigmoid')(h)\n",
    "\n",
    "model = models.Model(inputs=[i], outputs=[h])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 30s 1ms/step - loss: 0.5409 - binary_accuracy: 0.7347 - val_loss: 0.4118 - val_binary_accuracy: 0.8282\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 33s 1ms/step - loss: 0.3941 - binary_accuracy: 0.8318 - val_loss: 0.3940 - val_binary_accuracy: 0.8180\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 33s 1ms/step - loss: 0.3661 - binary_accuracy: 0.8427 - val_loss: 0.3473 - val_binary_accuracy: 0.8466\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 33s 1ms/step - loss: 0.3559 - binary_accuracy: 0.8469 - val_loss: 0.3387 - val_binary_accuracy: 0.8513\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 38s 2ms/step - loss: 0.3515 - binary_accuracy: 0.8509 - val_loss: 0.3720 - val_binary_accuracy: 0.8296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f950242f240>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train,\n",
    "          y=y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings and GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = layers.Input(shape=(x_train.shape[1],))\n",
    "\n",
    "embedding_layer = layers.Embedding(input_dim=vectors.shape[0],\n",
    "                                   output_dim=vectors.shape[1],\n",
    "                                   weights=[vectors],\n",
    "                                   trainable=False)\n",
    "\n",
    "h = embedding_layer(i)\n",
    "h = layers.GRU(128)(h)\n",
    "h = layers.Dropout(0.3)(h)\n",
    "h = layers.Dense(32, activation='relu')(h)\n",
    "h = layers.Dropout(0.3)(h)\n",
    "h = layers.Dense(1, activation='sigmoid')(h)\n",
    "\n",
    "model = models.Model(inputs=[i], outputs=[h])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=x_train,\n",
    "          y=y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (data3)",
   "language": "python",
   "name": "data3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
