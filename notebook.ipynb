{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis on IMDB large movie review dataset\n",
    "\n",
    "Get the dataset from [here](http://ai.stanford.edu/~amaas/data/sentiment/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import models, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text(text):\n",
    "    return text.lower().strip()\n",
    "\n",
    "def read_and_append_files(folder, label):\n",
    "    texts = []\n",
    "    for file in glob('./aclImdb/{0}/*.txt'.format(folder)):\n",
    "        with open(file, 'r') as f:\n",
    "            text = f.read()\n",
    "            text = parse_text(text)\n",
    "            texts.append((text, label))\n",
    "            \n",
    "    return texts\n",
    "\n",
    "def make_df(pos, neg):\n",
    "    df = pd.concat([pd.DataFrame(pos),\n",
    "                    pd.DataFrame(neg)])\\\n",
    "           .sample(frac=1)\\\n",
    "           .reset_index(drop=True)\n",
    "    df.columns = ['review', 'label']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = read_and_append_files('train/pos', 1)\n",
    "train_neg = read_and_append_files('train/neg', 0)\n",
    "\n",
    "test_pos = read_and_append_files('test/pos', 1)\n",
    "test_neg = read_and_append_files('test/neg', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = make_df(train_pos, train_neg)\n",
    "test_df = make_df(test_pos, test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i bought this at tower records after seeing th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a novel by remarque. a cast that looks great o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i enjoyed watching this well acted movie very ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this is an excellent film and one should not b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i really like 101 dalmations when it came out ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  i bought this at tower records after seeing th...      0\n",
       "1  a novel by remarque. a cast that looks great o...      0\n",
       "2  i enjoyed watching this well acted movie very ...      1\n",
       "3  this is an excellent film and one should not b...      1\n",
       "4  i really like 101 dalmations when it came out ...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is by far the worst movie i have ever see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why do i hate this? let me list the ways:&lt;br /...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nothing will ever top komodo with the lovely j...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i recently rented this video after seeing \"fin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was attracted to this film by its offbeat, l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  this is by far the worst movie i have ever see...      0\n",
       "1  why do i hate this? let me list the ways:<br /...      0\n",
       "2  nothing will ever top komodo with the lovely j...      0\n",
       "3  i recently rented this video after seeing \"fin...      1\n",
       "4  i was attracted to this film by its offbeat, l...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "I use [Fast Text pre trained embeddings](https://fasttext.cc/docs/en/english-vectors.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(train_df['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(fname, word_index):\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "    \n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        if tokens[0] in word_index:\n",
    "            w = word_index[tokens[0]]\n",
    "            embedding_matrix[w] = np.fromiter(map(float, tokens[1:]), 'float')\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 s, sys: 404 ms, total: 14.4 s\n",
      "Wall time: 14.3 s\n"
     ]
    }
   ],
   "source": [
    "%time vectors = load_vectors('/home/eric/Downloads/wiki-news-300d-1M.vec', t.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = layers.Embedding(input_dim=x_train.shape[1],\n",
    "                                   output_dim=vectors.shape[1],\n",
    "                                   weights=[vectors],\n",
    "                                   input_length=x_train.shape[1],\n",
    "                                   trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = t.texts_to_matrix(train_df['review'])\n",
    "y_train = train_df['label']\n",
    "\n",
    "x_test = t.texts_to_matrix(test_df['review'])\n",
    "y_test = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 88566), (25000,), (25000, 88566), (25000,))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = layers.Input(shape=(x_train.shape[1],))\n",
    "h = layers.Dense(units=1, activation='sigmoid')(i)\n",
    "model = models.Model(inputs=[i], outputs=[h])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 19s 772us/step - loss: 0.5740 - binary_accuracy: 0.7874 - val_loss: 0.5050 - val_binary_accuracy: 0.8166\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 19s 770us/step - loss: 0.4615 - binary_accuracy: 0.8371 - val_loss: 0.4429 - val_binary_accuracy: 0.8369\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 20s 788us/step - loss: 0.4136 - binary_accuracy: 0.8519 - val_loss: 0.4107 - val_binary_accuracy: 0.8475\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 19s 770us/step - loss: 0.3852 - binary_accuracy: 0.8605 - val_loss: 0.3902 - val_binary_accuracy: 0.8525\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 19s 766us/step - loss: 0.3653 - binary_accuracy: 0.8660 - val_loss: 0.3757 - val_binary_accuracy: 0.8574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fefce95d898>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train,\n",
    "          y=y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Embeddings and multi layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = layers.Input(shape=(x_train.shape[1],))\n",
    "h = embedding_layer(i)\n",
    "h = layers.Dense(128, activation='relu')(h)\n",
    "h = layers.Dropout(0.3)(h)\n",
    "h = layers.Dense(64, activation='relu')(h)\n",
    "h = layers.Dropout(0.3)(h)\n",
    "h = layers.Dense(32, activation='relu')(h)\n",
    "h = layers.Dropout(0.3)(h)\n",
    "h = layers.Dense(1, activation='sigmoid')(h)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 15s 609us/step - loss: 0.3503 - binary_accuracy: 0.8707 - val_loss: 0.3647 - val_binary_accuracy: 0.8603\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 15s 603us/step - loss: 0.3384 - binary_accuracy: 0.8739 - val_loss: 0.3559 - val_binary_accuracy: 0.8628\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 15s 607us/step - loss: 0.3284 - binary_accuracy: 0.8774 - val_loss: 0.3488 - val_binary_accuracy: 0.8648\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 15s 603us/step - loss: 0.3199 - binary_accuracy: 0.8804 - val_loss: 0.3434 - val_binary_accuracy: 0.8652\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 15s 601us/step - loss: 0.3127 - binary_accuracy: 0.8832 - val_loss: 0.3375 - val_binary_accuracy: 0.8676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fefcf5b0160>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train,\n",
    "          y=y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (data3)",
   "language": "python",
   "name": "data3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
